{"func_name": "_get_gamma", "func_src_before": "def _get_gamma(virtual_indexes, previous_indexes, method):\n    \"\"\"\n    Compute gamma (a.k.a 'm' or 'weight') for the linear interpolation\n    of quantiles.\n\n    virtual_indexes : array_like\n        The indexes where the percentile is supposed to be found in the sorted\n        sample.\n    previous_indexes : array_like\n        The floor values of virtual_indexes.\n    interpolation : dict\n        The interpolation method chosen, which may have a specific rule\n        modifying gamma.\n\n    gamma is usually the fractional part of virtual_indexes but can be modified\n    by the interpolation method.\n    \"\"\"\n    gamma = np.asanyarray(virtual_indexes - previous_indexes)\n    gamma = method[\"fix_gamma\"](gamma, virtual_indexes)\n    # Ensure both that we have an array, and that we keep the dtype\n    # (which may have been matched to the input array).\n    return np.asanyarray(gamma, dtype=virtual_indexes.dtype)", "func_src_after": "    def _repr_fits_vertical_(self) -> bool:\n        \"\"\"\n        Check length against max_rows.\n        \"\"\"\n        max_rows = get_option(\"display.max_rows\")\n        return len(self) <= max_rows", "line_changes": {"deleted": [{"line_no": 2, "char_start": 59, "char_end": 66, "line": "    \"\"\""}, {"line_no": 3, "char_start": 67, "char_end": 137, "line": "    Compute gamma (a.k.a 'm' or 'weight') for the linear interpolation"}, {"line_no": 4, "char_start": 138, "char_end": 155, "line": "    of quantiles."}, {"line_no": 18, "char_start": 608, "char_end": 669, "line": "    gamma = np.asanyarray(virtual_indexes - previous_indexes)"}, {"line_no": 19, "char_start": 670, "char_end": 725, "line": "    gamma = method[\"fix_gamma\"](gamma, virtual_indexes)"}, {"line_no": 20, "char_start": 726, "char_end": 793, "line": "    # Ensure both that we have an array, and that we keep the dtype"}, {"line_no": 21, "char_start": 794, "char_end": 849, "line": "    # (which may have been matched to the input array)."}, {"line_no": 22, "char_start": 850, "char_end": 910, "line": "    return np.asanyarray(gamma, dtype=virtual_indexes.dtype)"}], "added": [{"line_no": 2, "char_start": 44, "char_end": 55, "line": "        \"\"\""}, {"line_no": 3, "char_start": 56, "char_end": 94, "line": "        Check length against max_rows."}, {"line_no": 4, "char_start": 95, "char_end": 106, "line": "        \"\"\""}, {"line_no": 6, "char_start": 157, "char_end": 193, "line": "        return len(self) <= max_rows"}]}, "char_changes": {"deleted": [{"char_start": 5, "char_end": 600, "chars": "get_gamma(virtual_indexes, previous_indexes, method):\n    \"\"\"\n    Compute gamma (a.k.a 'm' or 'weight') for the linear interpolation\n    of quantiles.\n\n    virtual_indexes : array_like\n        The indexes where the percentile is supposed to be found in the sorted\n        sample.\n    previous_indexes : array_like\n        The floor values of virtual_indexes.\n    interpolation : dict\n        The interpolation method chosen, which may have a specific rule\n        modifying gamma.\n\n    gamma is usually the fractional part of virtual_indexes but can be modified\n    by the interpolation method.\n"}, {"char_start": 612, "char_end": 910, "chars": "gamma = np.asanyarray(virtual_indexes - previous_indexes)\n    gamma = method[\"fix_gamma\"](gamma, virtual_indexes)\n    # Ensure both that we have an array, and that we keep the dtype\n    # (which may have been matched to the input array).\n    return np.asanyarray(gamma, dtype=virtual_indexes.dtype)"}], "added": [{"char_start": 0, "char_end": 4, "chars": "    "}, {"char_start": 9, "char_end": 123, "chars": "repr_fits_vertical_(self) -> bool:\n        \"\"\"\n        Check length against max_rows.\n        \"\"\"\n        max_rows"}, {"char_start": 126, "char_end": 127, "chars": "g"}, {"char_start": 129, "char_end": 193, "chars": "_option(\"display.max_rows\")\n        return len(self) <= max_rows"}]}}
{"func_name": "ptp.partition", "func_src_before": "    def partition(self, *args, **kwargs):\n        warnings.warn(\"Warning: 'partition' will ignore the 'mask' \"\n                      f\"of the {self.__class__.__name__}.\",\n                      stacklevel=2)\n        return super().partition(*args, **kwargs)", "func_src_after": "    def _repr_latex_(self) -> str | None:\n        if get_option(\"styler.render.repr\") == \"latex\":\n            return self.to_latex()\n        return None", "line_changes": {"deleted": [{"line_no": 2, "char_start": 42, "char_end": 110, "line": "        warnings.warn(\"Warning: 'partition' will ignore the 'mask' \""}, {"line_no": 3, "char_start": 111, "char_end": 170, "line": "                      f\"of the {self.__class__.__name__}.\","}, {"line_no": 4, "char_start": 171, "char_end": 206, "line": "                      stacklevel=2)"}, {"line_no": 5, "char_start": 207, "char_end": 256, "line": "        return super().partition(*args, **kwargs)"}], "added": [{"line_no": 2, "char_start": 42, "char_end": 97, "line": "        if get_option(\"styler.render.repr\") == \"latex\":"}, {"line_no": 3, "char_start": 98, "char_end": 132, "line": "            return self.to_latex()"}, {"line_no": 4, "char_start": 133, "char_end": 152, "line": "        return None"}]}, "char_changes": {"deleted": [{"char_start": 8, "char_end": 256, "chars": "partition(self, *args, **kwargs):\n        warnings.warn(\"Warning: 'partition' will ignore the 'mask' \"\n                      f\"of the {self.__class__.__name__}.\",\n                      stacklevel=2)\n        return super().partition(*args, **kwargs)"}], "added": [{"char_start": 8, "char_end": 152, "chars": "_repr_latex_(self) -> str | None:\n        if get_option(\"styler.render.repr\") == \"latex\":\n            return self.to_latex()\n        return None"}]}}
{"func_name": "strptime.test_big_arrays", "func_src_before": "    def test_big_arrays(self):\n        L = (1 << 31) + 100000\n        a = np.empty(L, dtype=np.uint8)\n        with temppath(prefix=\"numpy_test_big_arrays_\", suffix=\".npz\") as tmp:\n            np.savez(tmp, a=a)\n            del a\n            npfile = np.load(tmp)\n            a = npfile['a']  # Should succeed\n            npfile.close()\n            del a  # Avoid pyflakes unused variable warning.", "func_src_after": "    def test_kind_both_ways(self, kind):\n        pytest.importorskip(\"scipy\")\n        df = DataFrame({\"x\": [1, 2, 3]})\n        df.plot(kind=kind)\n        getattr(df.plot, kind)()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 61, "line": "        L = (1 << 31) + 100000"}, {"line_no": 3, "char_start": 62, "char_end": 101, "line": "        a = np.empty(L, dtype=np.uint8)"}, {"line_no": 5, "char_start": 180, "char_end": 210, "line": "            np.savez(tmp, a=a)"}, {"line_no": 6, "char_start": 211, "char_end": 228, "line": "            del a"}, {"line_no": 7, "char_start": 229, "char_end": 262, "line": "            npfile = np.load(tmp)"}, {"line_no": 8, "char_start": 263, "char_end": 308, "line": "            a = npfile['a']  # Should succeed"}, {"line_no": 9, "char_start": 309, "char_end": 335, "line": "            npfile.close()"}, {"line_no": 10, "char_start": 336, "char_end": 396, "line": "            del a  # Avoid pyflakes unused variable warning."}], "added": [{"line_no": 3, "char_start": 78, "char_end": 118, "line": "        df = DataFrame({\"x\": [1, 2, 3]})"}, {"line_no": 4, "char_start": 119, "char_end": 145, "line": "        df.plot(kind=kind)"}, {"line_no": 5, "char_start": 146, "char_end": 178, "line": "        getattr(df.plot, kind)()"}]}, "char_changes": {"deleted": [{"char_start": 13, "char_end": 135, "chars": "big_arrays(self):\n        L = (1 << 31) + 100000\n        a = np.empty(L, dtype=np.uint8)\n        with temppath(prefix=\"num"}, {"char_start": 137, "char_end": 138, "chars": "_"}, {"char_start": 142, "char_end": 396, "chars": "_big_arrays_\", suffix=\".npz\") as tmp:\n            np.savez(tmp, a=a)\n            del a\n            npfile = np.load(tmp)\n            a = npfile['a']  # Should succeed\n            npfile.close()\n            del a  # Avoid pyflakes unused variable warning."}], "added": [{"char_start": 13, "char_end": 49, "chars": "kind_both_ways(self, kind):\n        "}, {"char_start": 55, "char_end": 178, "chars": ".importorskip(\"scipy\")\n        df = DataFrame({\"x\": [1, 2, 3]})\n        df.plot(kind=kind)\n        getattr(df.plot, kind)()"}]}}
{"func_name": "test_eps_positive", "func_src_before": "def test_eps_positive():\n    # np.finfo('g').eps should be positive on all platforms. If this isn't true\n    # then something may have gone wrong with the MachArLike, e.g. if\n    # np._core.getlimits._discovered_machar didn't work properly\n    assert np.finfo(np.longdouble).eps > 0.", "func_src_after": "    def test_get_loc_monotonic_nonunique(self):\n        cidx = CategoricalIndex(list(\"abbc\"))\n        result = cidx.get_loc(\"b\")\n        expected = slice(1, 3, None)\n        assert result == expected", "line_changes": {"deleted": [{"line_no": 2, "char_start": 25, "char_end": 104, "line": "    # np.finfo('g').eps should be positive on all platforms. If this isn't true"}, {"line_no": 3, "char_start": 105, "char_end": 174, "line": "    # then something may have gone wrong with the MachArLike, e.g. if"}, {"line_no": 4, "char_start": 175, "char_end": 239, "line": "    # np._core.getlimits._discovered_machar didn't work properly"}, {"line_no": 5, "char_start": 240, "char_end": 283, "line": "    assert np.finfo(np.longdouble).eps > 0."}], "added": [{"line_no": 2, "char_start": 48, "char_end": 93, "line": "        cidx = CategoricalIndex(list(\"abbc\"))"}, {"line_no": 3, "char_start": 94, "char_end": 128, "line": "        result = cidx.get_loc(\"b\")"}, {"line_no": 4, "char_start": 129, "char_end": 165, "line": "        expected = slice(1, 3, None)"}, {"line_no": 5, "char_start": 166, "char_end": 199, "line": "        assert result == expected"}]}, "char_changes": {"deleted": [{"char_start": 9, "char_end": 283, "chars": "eps_positive():\n    # np.finfo('g').eps should be positive on all platforms. If this isn't true\n    # then something may have gone wrong with the MachArLike, e.g. if\n    # np._core.getlimits._discovered_machar didn't work properly\n    assert np.finfo(np.longdouble).eps > 0."}], "added": [{"char_start": 0, "char_end": 4, "chars": "    "}, {"char_start": 13, "char_end": 199, "chars": "get_loc_monotonic_nonunique(self):\n        cidx = CategoricalIndex(list(\"abbc\"))\n        result = cidx.get_loc(\"b\")\n        expected = slice(1, 3, None)\n        assert result == expected"}]}}
{"func_name": "_signs.test_float_repr", "func_src_before": "    def test_float_repr(self):\n        # long double test cannot work, because eval goes through a python\n        # float\n        for t in [np.float32, np.float64]:\n            self._test_type_repr(t)\n\n        def test_equal_nbytes(self):\n            for type in types:\n                x = type(0)\n                assert_(sys.getsizeof(x) > x.nbytes)\n\n        def test_error(self):\n            d = np.float32()\n            assert_raises(TypeError, d.__sizeof__, \"a\")", "func_src_after": "    def test_shift_empty(self):\n        # Regression test for GH#8019\n        df = DataFrame({\"foo\": []})\n        rs = df.shift(-1)\n\n        tm.assert_frame_equal(df, rs)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 106, "char_end": 121, "line": "        # float"}, {"line_no": 4, "char_start": 122, "char_end": 164, "line": "        for t in [np.float32, np.float64]:"}, {"line_no": 5, "char_start": 165, "char_end": 200, "line": "            self._test_type_repr(t)"}, {"line_no": 11, "char_start": 351, "char_end": 351, "line": ""}, {"line_no": 12, "char_start": 352, "char_end": 381, "line": "        def test_error(self):"}, {"line_no": 13, "char_start": 382, "char_end": 410, "line": "            d = np.float32()"}], "added": [{"line_no": 3, "char_start": 70, "char_end": 105, "line": "        df = DataFrame({\"foo\": []})"}, {"line_no": 4, "char_start": 106, "char_end": 131, "line": "        rs = df.shift(-1)"}]}, "char_changes": {"deleted": [{"char_start": 13, "char_end": 23, "chars": "float_repr"}, {"char_start": 41, "char_end": 349, "chars": "long double test cannot work, because eval goes through a python\n        # float\n        for t in [np.float32, np.float64]:\n            self._test_type_repr(t)\n\n        def test_equal_nbytes(self):\n            for type in types:\n                x = type(0)\n                assert_(sys.getsizeof(x) > x.nbytes"}, {"char_start": 351, "char_end": 352, "chars": "\n"}, {"char_start": 360, "char_end": 410, "chars": "def test_error(self):\n            d = np.float32()"}, {"char_start": 419, "char_end": 423, "chars": "    "}, {"char_start": 432, "char_end": 465, "chars": "ises(TypeError, d.__sizeof__, \"a\""}], "added": [{"char_start": 13, "char_end": 24, "chars": "shift_empty"}, {"char_start": 42, "char_end": 144, "chars": "Regression test for GH#8019\n        df = DataFrame({\"foo\": []})\n        rs = df.shift(-1)\n\n        tm."}, {"char_start": 151, "char_end": 152, "chars": "f"}, {"char_start": 154, "char_end": 169, "chars": "me_equal(df, rs"}]}}
{"func_name": "dispatched_two_arg.test_ndarray", "func_src_before": "    def test_ndarray(self):\n        array = np.array(1)\n\n        args = _get_implementing_args([array])\n        assert_equal(list(args), [array])\n\n        args = _get_implementing_args([array, array])\n        assert_equal(list(args), [array])\n\n        args = _get_implementing_args([array, 1])\n        assert_equal(list(args), [array])\n\n        args = _get_implementing_args([1, array])\n        assert_equal(list(args), [array])", "func_src_after": "    def test_unique_data_ownership(self):\n        # it works! GH#1807\n        Series(Series([\"a\", \"c\", \"b\"]).unique()).sort_values()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 28, "char_end": 55, "line": "        array = np.array(1)"}, {"line_no": 8, "char_start": 201, "char_end": 242, "line": "        assert_equal(list(args), [array])"}], "added": [{"line_no": 2, "char_start": 42, "char_end": 69, "line": "        # it works! GH#1807"}, {"line_no": 3, "char_start": 70, "char_end": 132, "line": "        Series(Series([\"a\", \"c\", \"b\"]).unique()).sort_values()"}]}, "char_changes": {"deleted": [{"char_start": 13, "char_end": 427, "chars": "ndarray(self):\n        array = np.array(1)\n\n        args = _get_implementing_args([array])\n        assert_equal(list(args), [array])\n\n        args = _get_implementing_args([array, array])\n        assert_equal(list(args), [array])\n\n        args = _get_implementing_args([array, 1])\n        assert_equal(list(args), [array])\n\n        args = _get_implementing_args([1, array])\n        assert_equal(list(args), [array]"}], "added": [{"char_start": 13, "char_end": 131, "chars": "unique_data_ownership(self):\n        # it works! GH#1807\n        Series(Series([\"a\", \"c\", \"b\"]).unique()).sort_values("}]}}
{"func_name": "assert_mask_equal.teardown_method", "func_src_before": "    def teardown_method(self):\n        np.seterr(**self.err_status)", "func_src_after": "    def __enter__(self) -> Self:\n        return self", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 67, "line": "        np.seterr(**self.err_status)"}], "added": [{"line_no": 2, "char_start": 33, "char_end": 52, "line": "        return self"}]}, "char_changes": {"deleted": [{"char_start": 8, "char_end": 67, "chars": "teardown_method(self):\n        np.seterr(**self.err_status)"}], "added": [{"char_start": 8, "char_end": 52, "chars": "__enter__(self) -> Self:\n        return self"}]}}
{"func_name": "isexternal", "func_src_before": "def isexternal(var):\n    return 'attrspec' in var and 'external' in var['attrspec']", "func_src_after": "def left_df():\n    return DataFrame({\"a\": [20, 10, 0]}, index=[2, 1, 0])", "line_changes": {"deleted": [], "added": []}, "char_changes": {"deleted": [{"char_start": 4, "char_end": 18, "chars": "isexternal(var"}, {"char_start": 32, "char_end": 33, "chars": "'"}, {"char_start": 35, "char_end": 83, "chars": "trspec' in var and 'external' in var['attrspec']"}], "added": [{"char_start": 4, "char_end": 12, "chars": "left_df("}, {"char_start": 26, "char_end": 27, "chars": "D"}, {"char_start": 29, "char_end": 72, "chars": "aFrame({\"a\": [20, 10, 0]}, index=[2, 1, 0])"}]}}
{"func_name": "_parse_docstrings.__len__", "func_src_before": "    def __len__(self, /) -> int:\n        \"\"\"Implement ``len(self)``.\"\"\"\n        raise NotImplementedError", "func_src_after": "    def _is_view(self) -> bool_t:\n        \"\"\"Return boolean indicating if self is view of another array\"\"\"\n        return self._mgr.is_view", "line_changes": {"deleted": [{"line_no": 3, "char_start": 72, "char_end": 105, "line": "        raise NotImplementedError"}], "added": [{"line_no": 3, "char_start": 107, "char_end": 139, "line": "        return self._mgr.is_view"}]}, "char_changes": {"deleted": [{"char_start": 9, "char_end": 15, "chars": "_len__"}, {"char_start": 20, "char_end": 23, "chars": ", /"}, {"char_start": 28, "char_end": 30, "chars": "in"}, {"char_start": 44, "char_end": 105, "chars": "Implement ``len(self)``.\"\"\"\n        raise NotImplementedError"}], "added": [{"char_start": 9, "char_end": 16, "chars": "is_view"}, {"char_start": 26, "char_end": 31, "chars": "bool_"}, {"char_start": 45, "char_end": 139, "chars": "Return boolean indicating if self is view of another array\"\"\"\n        return self._mgr.is_view"}]}}
{"func_name": "getpydocsign", "func_src_before": "def getpydocsign(a, var):\n    global lcb_map\n    if isfunction(var):\n        if 'result' in var:\n            af = var['result']\n        else:\n            af = var['name']\n        if af in var['vars']:\n            return getpydocsign(af, var['vars'][af])\n        else:\n            errmess('getctype: function %s has no return value?!\\n' % af)\n        return '', ''\n    sig, sigout = a, a\n    opt = ''\n    if isintent_in(var):\n        opt = 'input'\n    elif isintent_inout(var):\n        opt = 'in/output'\n    out_a = a\n    if isintent_out(var):\n        for k in var['intent']:\n            if k[:4] == 'out=':\n                out_a = k[4:]\n                break\n    init = ''\n    ctype = getctype(var)\n\n    if hasinitvalue(var):\n        init, showinit = getinit(a, var)\n        init = ', optional\\\\n    Default: %s' % showinit\n    if isscalar(var):\n        if isintent_inout(var):\n            sig = '%s : %s rank-0 array(%s,\\'%s\\')%s' % (a, opt, c2py_map[ctype],\n                                                         c2pycode_map[ctype], init)\n        else:\n            sig = '%s : %s %s%s' % (a, opt, c2py_map[ctype], init)\n        sigout = '%s : %s' % (out_a, c2py_map[ctype])\n    elif isstring(var):\n        if isintent_inout(var):\n            sig = '%s : %s rank-0 array(string(len=%s),\\'c\\')%s' % (\n                a, opt, getstrlength(var), init)\n        else:\n            sig = '%s : %s string(len=%s)%s' % (\n                a, opt, getstrlength(var), init)\n        sigout = '%s : string(len=%s)' % (out_a, getstrlength(var))\n    elif isarray(var):\n        dim = var['dimension']\n        rank = repr(len(dim))\n        sig = '%s : %s rank-%s array(\\'%s\\') with bounds (%s)%s' % (a, opt, rank,\n                                                                    c2pycode_map[\n                                                                        ctype],\n                                                                    ','.join(dim), init)\n        if a == out_a:\n            sigout = '%s : rank-%s array(\\'%s\\') with bounds (%s)'\\\n                % (a, rank, c2pycode_map[ctype], ','.join(dim))\n        else:\n            sigout = '%s : rank-%s array(\\'%s\\') with bounds (%s) and %s storage'\\\n                % (out_a, rank, c2pycode_map[ctype], ','.join(dim), a)\n    elif isexternal(var):\n        ua = ''\n        if a in lcb_map and lcb_map[a] in lcb2_map and 'argname' in lcb2_map[lcb_map[a]]:\n            ua = lcb2_map[lcb_map[a]]['argname']\n            if not ua == a:\n                ua = ' => %s' % ua\n            else:\n                ua = ''\n        sig = '%s : call-back function%s' % (a, ua)\n        sigout = sig\n    else:\n        errmess(\n            'getpydocsign: Could not resolve docsignature for \"%s\".\\n' % a)\n    return sig, sigout", "func_src_after": "def get_rename_function(mapper):\n    \"\"\"\n    Returns a function that will map names/labels, dependent if mapper\n    is a dict, Series or just a function.\n    \"\"\"\n\n    def f(x):\n        if x in mapper:\n            return mapper[x]\n        else:\n            return x\n\n    return f if isinstance(mapper, (abc.Mapping, ABCSeries)) else mapper", "line_changes": {"deleted": [{"line_no": 2, "char_start": 26, "char_end": 44, "line": "    global lcb_map"}, {"line_no": 3, "char_start": 45, "char_end": 68, "line": "    if isfunction(var):"}, {"line_no": 4, "char_start": 69, "char_end": 96, "line": "        if 'result' in var:"}, {"line_no": 5, "char_start": 97, "char_end": 127, "line": "            af = var['result']"}, {"line_no": 6, "char_start": 128, "char_end": 141, "line": "        else:"}, {"line_no": 7, "char_start": 142, "char_end": 170, "line": "            af = var['name']"}, {"line_no": 8, "char_start": 171, "char_end": 200, "line": "        if af in var['vars']:"}, {"line_no": 9, "char_start": 201, "char_end": 253, "line": "            return getpydocsign(af, var['vars'][af])"}, {"line_no": 10, "char_start": 254, "char_end": 267, "line": "        else:"}, {"line_no": 11, "char_start": 268, "char_end": 341, "line": "            errmess('getctype: function %s has no return value?!\\n' % af)"}, {"line_no": 12, "char_start": 342, "char_end": 363, "line": "        return '', ''"}, {"line_no": 13, "char_start": 364, "char_end": 386, "line": "    sig, sigout = a, a"}, {"line_no": 14, "char_start": 387, "char_end": 399, "line": "    opt = ''"}, {"line_no": 16, "char_start": 425, "char_end": 446, "line": "        opt = 'input'"}, {"line_no": 17, "char_start": 447, "char_end": 476, "line": "    elif isintent_inout(var):"}, {"line_no": 18, "char_start": 477, "char_end": 502, "line": "        opt = 'in/output'"}, {"line_no": 19, "char_start": 503, "char_end": 516, "line": "    out_a = a"}, {"line_no": 20, "char_start": 517, "char_end": 542, "line": "    if isintent_out(var):"}, {"line_no": 21, "char_start": 543, "char_end": 574, "line": "        for k in var['intent']:"}, {"line_no": 22, "char_start": 575, "char_end": 606, "line": "            if k[:4] == 'out=':"}, {"line_no": 23, "char_start": 607, "char_end": 636, "line": "                out_a = k[4:]"}, {"line_no": 24, "char_start": 637, "char_end": 658, "line": "                break"}, {"line_no": 25, "char_start": 659, "char_end": 672, "line": "    init = ''"}, {"line_no": 26, "char_start": 673, "char_end": 698, "line": "    ctype = getctype(var)"}], "added": [{"line_no": 2, "char_start": 33, "char_end": 40, "line": "    \"\"\""}, {"line_no": 3, "char_start": 41, "char_end": 111, "line": "    Returns a function that will map names/labels, dependent if mapper"}, {"line_no": 4, "char_start": 112, "char_end": 153, "line": "    is a dict, Series or just a function."}, {"line_no": 5, "char_start": 154, "char_end": 161, "line": "    \"\"\""}]}, "char_changes": {"deleted": [{"char_start": 7, "char_end": 421, "chars": "pydocsign(a, var):\n    global lcb_map\n    if isfunction(var):\n        if 'result' in var:\n            af = var['result']\n        else:\n            af = var['name']\n        if af in var['vars']:\n            return getpydocsign(af, var['vars'][af])\n        else:\n            errmess('getctype: function %s has no return value?!\\n' % af)\n        return '', ''\n    sig, sigout = a, a\n    opt = ''\n    if isintent_in(va"}, {"char_start": 429, "char_end": 430, "chars": " "}, {"char_start": 430, "char_end": 2757, "chars": "   opt = 'input'\n    elif isintent_inout(var):\n        opt = 'in/output'\n    out_a = a\n    if isintent_out(var):\n        for k in var['intent']:\n            if k[:4] == 'out=':\n                out_a = k[4:]\n                break\n    init = ''\n    ctype = getctype(var)\n\n    if hasinitvalue(var):\n        init, showinit = getinit(a, var)\n        init = ', optional\\\\n    Default: %s' % showinit\n    if isscalar(var):\n        if isintent_inout(var):\n            sig = '%s : %s rank-0 array(%s,\\'%s\\')%s' % (a, opt, c2py_map[ctype],\n                                                         c2pycode_map[ctype], init)\n        else:\n            sig = '%s : %s %s%s' % (a, opt, c2py_map[ctype], init)\n        sigout = '%s : %s' % (out_a, c2py_map[ctype])\n    elif isstring(var):\n        if isintent_inout(var):\n            sig = '%s : %s rank-0 array(string(len=%s),\\'c\\')%s' % (\n                a, opt, getstrlength(var), init)\n        else:\n            sig = '%s : %s string(len=%s)%s' % (\n                a, opt, getstrlength(var), init)\n        sigout = '%s : string(len=%s)' % (out_a, getstrlength(var))\n    elif isarray(var):\n        dim = var['dimension']\n        rank = repr(len(dim))\n        sig = '%s : %s rank-%s array(\\'%s\\') with bounds (%s)%s' % (a, opt, rank,\n                                                                    c2pycode_map[\n                                                                        ctype],\n                                                                    ','.join(dim), init)\n        if a == out_a:\n            sigout = '%s : rank-%s array(\\'%s\\') with bounds (%s)'\\\n                % (a, rank, c2pycode_map[ctype], ','.join(dim))\n        else:\n            sigout = '%s : rank-%s array(\\'%s\\') with bounds (%s) and %s storage'\\\n                % (out_a, rank, c2pycode_map[ctype], ','.join(dim), a)\n    elif isexternal(var):\n        ua = ''\n        if a in lcb_map and lcb_map[a] in lcb2_map and 'argname' in lcb2_map[lcb_map[a]]:\n            ua = lcb2_map[lcb_map[a]]['argname']\n            if not ua == a:\n                ua = ' => %s' % ua\n            else:\n                ua = ''\n        sig = '%s : call-back function%s' % (a, ua)\n        sigout = sig\n    else:\n        errmess(\n            'getpydocsign: Could not resolve docsignature for \"%s\".\\n' % a)\n    return sig, sigout"}], "added": [{"char_start": 7, "char_end": 338, "chars": "_rename_function(mapper):\n    \"\"\"\n    Returns a function that will map names/labels, dependent if mapper\n    is a dict, Series or just a function.\n    \"\"\"\n\n    def f(x):\n        if x in mapper:\n            return mapper[x]\n        else:\n            return x\n\n    return f if isinstance(mapper, (abc.Mapping, ABCSeries)) else mapper"}]}}
{"func_name": "assert_mask_equal.test_mod", "func_src_before": "    def test_mod(self):\n        # Tests mod\n        (x, y, a10, m1, m2, xm, ym, z, zm, xf) = self.d\n        assert_equal(mod(x, y), mod(xm, ym))\n        test = mod(ym, xm)\n        assert_equal(test, np.mod(ym, xm))\n        assert_equal(test.mask, mask_or(xm.mask, ym.mask))\n        test = mod(xm, ym)\n        assert_equal(test, np.mod(xm, ym))\n        assert_equal(test.mask, mask_or(mask_or(xm.mask, ym.mask), (ym == 0)))", "func_src_after": "    def test_arith_series_with_scalar(self, data, all_arithmetic_operators):\n        super().test_arith_series_with_scalar(data, all_arithmetic_operators)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 24, "char_end": 43, "line": "        # Tests mod"}, {"line_no": 3, "char_start": 44, "char_end": 99, "line": "        (x, y, a10, m1, m2, xm, ym, z, zm, xf) = self.d"}, {"line_no": 4, "char_start": 100, "char_end": 144, "line": "        assert_equal(mod(x, y), mod(xm, ym))"}, {"line_no": 5, "char_start": 145, "char_end": 171, "line": "        test = mod(ym, xm)"}, {"line_no": 6, "char_start": 172, "char_end": 214, "line": "        assert_equal(test, np.mod(ym, xm))"}, {"line_no": 7, "char_start": 215, "char_end": 273, "line": "        assert_equal(test.mask, mask_or(xm.mask, ym.mask))"}, {"line_no": 8, "char_start": 274, "char_end": 300, "line": "        test = mod(xm, ym)"}, {"line_no": 9, "char_start": 301, "char_end": 343, "line": "        assert_equal(test, np.mod(xm, ym))"}, {"line_no": 10, "char_start": 344, "char_end": 422, "line": "        assert_equal(test.mask, mask_or(mask_or(xm.mask, ym.mask), (ym == 0)))"}], "added": [{"line_no": 2, "char_start": 77, "char_end": 154, "line": "        super().test_arith_series_with_scalar(data, all_arithmetic_operators)"}]}, "char_changes": {"deleted": [{"char_start": 13, "char_end": 421, "chars": "mod(self):\n        # Tests mod\n        (x, y, a10, m1, m2, xm, ym, z, zm, xf) = self.d\n        assert_equal(mod(x, y), mod(xm, ym))\n        test = mod(ym, xm)\n        assert_equal(test, np.mod(ym, xm))\n        assert_equal(test.mask, mask_or(xm.mask, ym.mask))\n        test = mod(xm, ym)\n        assert_equal(test, np.mod(xm, ym))\n        assert_equal(test.mask, mask_or(mask_or(xm.mask, ym.mask), (ym == 0))"}], "added": [{"char_start": 13, "char_end": 153, "chars": "arith_series_with_scalar(self, data, all_arithmetic_operators):\n        super().test_arith_series_with_scalar(data, all_arithmetic_operators"}]}}
{"func_name": "test_iter_no_broadcast.test_basic", "func_src_before": "    def test_basic(self):\n        # Test nested iteration basic usage\n        a = arange(12).reshape(2, 3, 2)\n\n        i, j = np.nested_iters(a, [[0], [1, 2]])\n        vals = [list(j) for _ in i]\n        assert_equal(vals, [[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11]])\n\n        i, j = np.nested_iters(a, [[0, 1], [2]])\n        vals = [list(j) for _ in i]\n        assert_equal(vals, [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11]])\n\n        i, j = np.nested_iters(a, [[0, 2], [1]])\n        vals = [list(j) for _ in i]\n        assert_equal(vals, [[0, 2, 4], [1, 3, 5], [6, 8, 10], [7, 9, 11]])", "func_src_after": "def test_is_iso_format(fmt, expected):\n    # see gh-41047\n    result = strptime._test_format_is_iso(fmt)\n    assert result == expected", "line_changes": {"deleted": [{"line_no": 2, "char_start": 26, "char_end": 69, "line": "        # Test nested iteration basic usage"}, {"line_no": 3, "char_start": 70, "char_end": 109, "line": "        a = arange(12).reshape(2, 3, 2)"}], "added": [{"line_no": 2, "char_start": 39, "char_end": 57, "line": "    # see gh-41047"}, {"line_no": 3, "char_start": 58, "char_end": 104, "line": "    result = strptime._test_format_is_iso(fmt)"}, {"line_no": 4, "char_start": 105, "char_end": 134, "line": "    assert result == expected"}]}, "char_changes": {"deleted": [{"char_start": 0, "char_end": 4, "chars": "    "}, {"char_start": 13, "char_end": 592, "chars": "basic(self):\n        # Test nested iteration basic usage\n        a = arange(12).reshape(2, 3, 2)\n\n        i, j = np.nested_iters(a, [[0], [1, 2]])\n        vals = [list(j) for _ in i]\n        assert_equal(vals, [[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11]])\n\n        i, j = np.nested_iters(a, [[0, 1], [2]])\n        vals = [list(j) for _ in i]\n        assert_equal(vals, [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11]])\n\n        i, j = np.nested_iters(a, [[0, 2], [1]])\n        vals = [list(j) for _ in i]\n        assert_equal(vals, [[0, 2, 4], [1, 3, 5], [6, 8, 10], [7, 9, 11]])"}], "added": [{"char_start": 9, "char_end": 134, "chars": "is_iso_format(fmt, expected):\n    # see gh-41047\n    result = strptime._test_format_is_iso(fmt)\n    assert result == expected"}]}}
{"func_name": "isreal", "func_src_before": "def isreal(var):\n    return isscalar(var) and var.get('typespec') == 'real'", "func_src_after": "def no_bar():\n    return bar_grad()", "line_changes": {"deleted": [], "added": []}, "char_changes": {"deleted": [{"char_start": 4, "char_end": 14, "chars": "isreal(var"}, {"char_start": 28, "char_end": 75, "chars": "isscalar(var) and var.get('typespec') == 'real'"}], "added": [{"char_start": 4, "char_end": 8, "chars": "no_b"}, {"char_start": 10, "char_end": 11, "chars": "("}, {"char_start": 25, "char_end": 35, "chars": "bar_grad()"}]}}
{"func_name": "test_functions_single_location.test_cache", "func_src_before": "    def test_cache(self):\n        assert_(ndpointer(dtype=np.float64) is ndpointer(dtype=np.float64))\n\n        # shapes are normalized\n        assert_(ndpointer(shape=2) is ndpointer(shape=(2,)))\n\n        # 1.12 <= v < 1.16 had a bug that made these fail\n        assert_(ndpointer(shape=2) is not ndpointer(ndim=2))\n        assert_(ndpointer(ndim=2) is not ndpointer(shape=2))", "func_src_after": "    def f(x):\n        if x.index[0] == df.index[0]:\n            return np.nan\n        return x.iloc[-1]", "line_changes": {"deleted": [{"line_no": 2, "char_start": 26, "char_end": 101, "line": "        assert_(ndpointer(dtype=np.float64) is ndpointer(dtype=np.float64))"}], "added": [{"line_no": 2, "char_start": 14, "char_end": 51, "line": "        if x.index[0] == df.index[0]:"}, {"line_no": 3, "char_start": 52, "char_end": 77, "line": "            return np.nan"}, {"line_no": 4, "char_start": 78, "char_end": 103, "line": "        return x.iloc[-1]"}]}, "char_changes": {"deleted": [{"char_start": 8, "char_end": 376, "chars": "test_cache(self):\n        assert_(ndpointer(dtype=np.float64) is ndpointer(dtype=np.float64))\n\n        # shapes are normalized\n        assert_(ndpointer(shape=2) is ndpointer(shape=(2,)))\n\n        # 1.12 <= v < 1.16 had a bug that made these fail\n        assert_(ndpointer(shape=2) is not ndpointer(ndim=2))\n        assert_(ndpointer(ndim=2) is not ndpointer(shape=2))"}], "added": [{"char_start": 8, "char_end": 103, "chars": "f(x):\n        if x.index[0] == df.index[0]:\n            return np.nan\n        return x.iloc[-1]"}]}}
{"func_name": "has_f90_compiler", "func_src_before": "def has_f90_compiler():\n    return _get_compiler_status()[2]", "func_src_after": "    def mask_all(self) -> bool:\n        return bool(self.mask.all())", "line_changes": {"deleted": [], "added": []}, "char_changes": {"deleted": [{"char_start": 4, "char_end": 5, "chars": "h"}, {"char_start": 7, "char_end": 24, "chars": "_f90_compiler():\n"}, {"char_start": 35, "char_end": 60, "chars": "_get_compiler_status()[2]"}], "added": [{"char_start": 0, "char_end": 4, "chars": "    "}, {"char_start": 8, "char_end": 9, "chars": "m"}, {"char_start": 11, "char_end": 34, "chars": "k_all(self) -> bool:\n  "}, {"char_start": 38, "char_end": 40, "chars": "  "}, {"char_start": 47, "char_end": 68, "chars": "bool(self.mask.all())"}]}}
{"func_name": "fft1.test_all_1d_norm_preserving", "func_src_before": "    def test_all_1d_norm_preserving(self):\n        # verify that round-trip transforms are norm-preserving\n        x = random(30)\n        x_norm = np.linalg.norm(x)\n        n = x.size * 2\n        func_pairs = [(np.fft.fft, np.fft.ifft),\n                      (np.fft.rfft, np.fft.irfft),\n                      # hfft: order so the first function takes x.size samples\n                      #       (necessary for comparison to x_norm above)\n                      (np.fft.ihfft, np.fft.hfft),\n                      ]\n        for forw, back in func_pairs:\n            for n in [x.size, 2*x.size]:\n                for norm in [None, 'backward', 'ortho', 'forward']:\n                    tmp = forw(x, n=n, norm=norm)\n                    tmp = back(tmp, n=n, norm=norm)\n                    assert_allclose(x_norm,\n                                    np.linalg.norm(tmp), atol=1e-6)", "func_src_after": "        def set_caption_from_template(styler, a, b):\n            return styler.set_caption(f\"Dataframe with a = {a} and b = {b}\")", "line_changes": {"deleted": [{"line_no": 1, "char_start": 1, "char_end": 43, "line": "    def test_all_1d_norm_preserving(self):"}, {"line_no": 2, "char_start": 43, "char_end": 106, "line": "        # verify that round-trip transforms are norm-preserving"}, {"line_no": 3, "char_start": 107, "char_end": 129, "line": "        x = random(30)"}, {"line_no": 4, "char_start": 130, "char_end": 164, "line": "        x_norm = np.linalg.norm(x)"}, {"line_no": 5, "char_start": 165, "char_end": 187, "line": "        n = x.size * 2"}, {"line_no": 6, "char_start": 188, "char_end": 236, "line": "        func_pairs = [(np.fft.fft, np.fft.ifft),"}, {"line_no": 7, "char_start": 237, "char_end": 287, "line": "                      (np.fft.rfft, np.fft.irfft),"}, {"line_no": 8, "char_start": 288, "char_end": 366, "line": "                      # hfft: order so the first function takes x.size samples"}, {"line_no": 9, "char_start": 367, "char_end": 439, "line": "                      #       (necessary for comparison to x_norm above)"}, {"line_no": 10, "char_start": 440, "char_end": 490, "line": "                      (np.fft.ihfft, np.fft.hfft),"}, {"line_no": 11, "char_start": 491, "char_end": 514, "line": "                      ]"}, {"line_no": 12, "char_start": 515, "char_end": 552, "line": "        for forw, back in func_pairs:"}, {"line_no": 13, "char_start": 553, "char_end": 593, "line": "            for n in [x.size, 2*x.size]:"}, {"line_no": 14, "char_start": 594, "char_end": 661, "line": "                for norm in [None, 'backward', 'ortho', 'forward']:"}, {"line_no": 15, "char_start": 662, "char_end": 711, "line": "                    tmp = forw(x, n=n, norm=norm)"}, {"line_no": 16, "char_start": 712, "char_end": 763, "line": "                    tmp = back(tmp, n=n, norm=norm)"}, {"line_no": 17, "char_start": 764, "char_end": 807, "line": "                    assert_allclose(x_norm,"}, {"line_no": 18, "char_start": 808, "char_end": 875, "line": "                                    np.linalg.norm(tmp), atol=1e-6)"}], "added": [{"line_no": 2, "char_start": 53, "char_end": 129, "line": "            return styler.set_caption(f\"Dataframe with a = {a} and b = {b}\")"}]}, "char_changes": {"deleted": [{"char_start": 4, "char_end": 874, "chars": "def test_all_1d_norm_preserving(self):\n        # verify that round-trip transforms are norm-preserving\n        x = random(30)\n        x_norm = np.linalg.norm(x)\n        n = x.size * 2\n        func_pairs = [(np.fft.fft, np.fft.ifft),\n                      (np.fft.rfft, np.fft.irfft),\n                      # hfft: order so the first function takes x.size samples\n                      #       (necessary for comparison to x_norm above)\n                      (np.fft.ihfft, np.fft.hfft),\n                      ]\n        for forw, back in func_pairs:\n            for n in [x.size, 2*x.size]:\n                for norm in [None, 'backward', 'ortho', 'forward']:\n                    tmp = forw(x, n=n, norm=norm)\n                    tmp = back(tmp, n=n, norm=norm)\n                    assert_allclose(x_norm,\n                                    np.linalg.norm(tmp), atol=1e-6"}], "added": [{"char_start": 0, "char_end": 4, "chars": "    "}, {"char_start": 12, "char_end": 128, "chars": "set_caption_from_template(styler, a, b):\n            return styler.set_caption(f\"Dataframe with a = {a} and b = {b}\""}]}}
{"func_name": "test_outer_out_param.test_simple", "func_src_before": "    def test_simple(self):\n        [x, y] = np.indices((4, 3))\n        assert_array_equal(x, np.array([[0, 0, 0],\n                                        [1, 1, 1],\n                                        [2, 2, 2],\n                                        [3, 3, 3]]))\n        assert_array_equal(y, np.array([[0, 1, 2],\n                                        [0, 1, 2],\n                                        [0, 1, 2],\n                                        [0, 1, 2]]))", "func_src_after": "    def test_plot_ts_area_stacked(self, ts):\n        _check_plot_works(ts.plot.area, stacked=False)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 27, "char_end": 62, "line": "        [x, y] = np.indices((4, 3))"}, {"line_no": 3, "char_start": 63, "char_end": 113, "line": "        assert_array_equal(x, np.array([[0, 0, 0],"}, {"line_no": 4, "char_start": 114, "char_end": 164, "line": "                                        [1, 1, 1],"}, {"line_no": 5, "char_start": 165, "char_end": 215, "line": "                                        [2, 2, 2],"}, {"line_no": 6, "char_start": 216, "char_end": 268, "line": "                                        [3, 3, 3]]))"}, {"line_no": 7, "char_start": 269, "char_end": 319, "line": "        assert_array_equal(y, np.array([[0, 1, 2],"}, {"line_no": 8, "char_start": 320, "char_end": 370, "line": "                                        [0, 1, 2],"}, {"line_no": 9, "char_start": 371, "char_end": 421, "line": "                                        [0, 1, 2],"}, {"line_no": 10, "char_start": 422, "char_end": 474, "line": "                                        [0, 1, 2]]))"}], "added": [{"line_no": 2, "char_start": 45, "char_end": 99, "line": "        _check_plot_works(ts.plot.area, stacked=False)"}]}, "char_changes": {"deleted": [{"char_start": 13, "char_end": 473, "chars": "simple(self):\n        [x, y] = np.indices((4, 3))\n        assert_array_equal(x, np.array([[0, 0, 0],\n                                        [1, 1, 1],\n                                        [2, 2, 2],\n                                        [3, 3, 3]]))\n        assert_array_equal(y, np.array([[0, 1, 2],\n                                        [0, 1, 2],\n                                        [0, 1, 2],\n                                        [0, 1, 2]])"}], "added": [{"char_start": 13, "char_end": 98, "chars": "plot_ts_area_stacked(self, ts):\n        _check_plot_works(ts.plot.area, stacked=False"}]}}
{"func_name": "asmatrix._collapse", "func_src_before": "    def _collapse(self, axis):\n        \"\"\"A convenience function for operations that want to collapse\n        to a scalar like _align, but are using keepdims=True\n        \"\"\"\n        if axis is None:\n            return self[0, 0]\n        else:\n            return self", "func_src_after": "    def f(x):\n        s = Series([1, 2], index=[\"a\", \"b\"])\n        return s", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 101, "line": "        \"\"\"A convenience function for operations that want to collapse"}, {"line_no": 3, "char_start": 102, "char_end": 162, "line": "        to a scalar like _align, but are using keepdims=True"}, {"line_no": 4, "char_start": 163, "char_end": 174, "line": "        \"\"\""}, {"line_no": 5, "char_start": 175, "char_end": 199, "line": "        if axis is None:"}, {"line_no": 6, "char_start": 200, "char_end": 229, "line": "            return self[0, 0]"}, {"line_no": 7, "char_start": 230, "char_end": 243, "line": "        else:"}], "added": [{"line_no": 2, "char_start": 14, "char_end": 58, "line": "        s = Series([1, 2], index=[\"a\", \"b\"])"}]}, "char_changes": {"deleted": [{"char_start": 8, "char_end": 248, "chars": "_collapse(self, axis):\n        \"\"\"A convenience function for operations that want to collapse\n        to a scalar like _align, but are using keepdims=True\n        \"\"\"\n        if axis is None:\n            return self[0, 0]\n        else:\n    "}, {"char_start": 264, "char_end": 267, "chars": "elf"}], "added": [{"char_start": 8, "char_end": 59, "chars": "f(x):\n        s = Series([1, 2], index=[\"a\", \"b\"])\n"}]}}
{"func_name": "_getfield_is_safe", "func_src_before": "def _getfield_is_safe(oldtype, newtype, offset):\n    \"\"\" Checks safety of getfield for object arrays.\n\n    As in _view_is_safe, we need to check that memory containing objects is not\n    reinterpreted as a non-object datatype and vice versa.\n\n    Parameters\n    ----------\n    oldtype : data-type\n        Data type of the original ndarray.\n    newtype : data-type\n        Data type of the field being accessed by ndarray.getfield\n    offset : int\n        Offset of the field being accessed by ndarray.getfield\n\n    Raises\n    ------\n    TypeError\n        If the field access is invalid\n\n    \"\"\"\n    if newtype.hasobject or oldtype.hasobject:\n        if offset == 0 and newtype == oldtype:\n            return\n        if oldtype.names is not None:\n            for name in oldtype.names:\n                if (oldtype.fields[name][1] == offset and\n                        oldtype.fields[name][0] == newtype):\n                    return\n        raise TypeError(\"Cannot get/set field of an object array\")\n    return", "func_src_after": "        def my_handler_raises(_):\n            raise TypeError(\"I raise for anything\")", "line_changes": {"deleted": [{"line_no": 1, "char_start": 1, "char_end": 49, "line": "def _getfield_is_safe(oldtype, newtype, offset):"}, {"line_no": 2, "char_start": 49, "char_end": 101, "line": "    \"\"\" Checks safety of getfield for object arrays."}], "added": [{"line_no": 1, "char_start": 1, "char_end": 34, "line": "        def my_handler_raises(_):"}, {"line_no": 2, "char_start": 34, "char_end": 85, "line": "            raise TypeError(\"I raise for anything\")"}]}, "char_changes": {"deleted": [{"char_start": 0, "char_end": 1008, "chars": "def _getfield_is_safe(oldtype, newtype, offset):\n    \"\"\" Checks safety of getfield for object arrays.\n\n    As in _view_is_safe, we need to check that memory containing objects is not\n    reinterpreted as a non-object datatype and vice versa.\n\n    Parameters\n    ----------\n    oldtype : data-type\n        Data type of the original ndarray.\n    newtype : data-type\n        Data type of the field being accessed by ndarray.getfield\n    offset : int\n        Offset of the field being accessed by ndarray.getfield\n\n    Raises\n    ------\n    TypeError\n        If the field access is invalid\n\n    \"\"\"\n    if newtype.hasobject or oldtype.hasobject:\n        if offset == 0 and newtype == oldtype:\n            return\n        if oldtype.names is not None:\n            for name in oldtype.names:\n                if (oldtype.fields[name][1] == offset and\n                        oldtype.fields[name][0] == newtype):\n                    return\n        raise TypeError(\"Cannot get/set field of an object array\")\n    return"}], "added": [{"char_start": 0, "char_end": 85, "chars": "        def my_handler_raises(_):\n            raise TypeError(\"I raise for anything\")"}]}}
{"func_name": "bmat.__invert__", "func_src_before": "    def __invert__(self: Array, /) -> Array:\n        \"\"\"\n        Performs the operation __invert__.\n        \"\"\"\n        if self.dtype not in _integer_or_boolean_dtypes:\n            raise TypeError(\"Only integer or boolean dtypes are allowed in __invert__\")\n        res = self._array.__invert__()\n        return self.__class__._new(res)", "func_src_after": "            def _constructor(self):\n                return NotADataFrame", "line_changes": {"deleted": [{"line_no": 1, "char_start": 1, "char_end": 45, "line": "    def __invert__(self: Array, /) -> Array:"}, {"line_no": 2, "char_start": 45, "char_end": 56, "line": "        \"\"\""}, {"line_no": 3, "char_start": 57, "char_end": 99, "line": "        Performs the operation __invert__."}, {"line_no": 4, "char_start": 100, "char_end": 111, "line": "        \"\"\""}, {"line_no": 5, "char_start": 112, "char_end": 168, "line": "        if self.dtype not in _integer_or_boolean_dtypes:"}, {"line_no": 6, "char_start": 169, "char_end": 256, "line": "            raise TypeError(\"Only integer or boolean dtypes are allowed in __invert__\")"}, {"line_no": 7, "char_start": 257, "char_end": 295, "line": "        res = self._array.__invert__()"}, {"line_no": 8, "char_start": 296, "char_end": 335, "line": "        return self.__class__._new(res)"}], "added": [{"line_no": 1, "char_start": 1, "char_end": 36, "line": "            def _constructor(self):"}, {"line_no": 2, "char_start": 36, "char_end": 72, "line": "                return NotADataFrame"}]}, "char_changes": {"deleted": [{"char_start": 4, "char_end": 335, "chars": "def __invert__(self: Array, /) -> Array:\n        \"\"\"\n        Performs the operation __invert__.\n        \"\"\"\n        if self.dtype not in _integer_or_boolean_dtypes:\n            raise TypeError(\"Only integer or boolean dtypes are allowed in __invert__\")\n        res = self._array.__invert__()\n        return self.__class__._new(res)"}], "added": [{"char_start": 4, "char_end": 72, "chars": "        def _constructor(self):\n                return NotADataFrame"}]}}
{"func_name": "test__replace_nan.test_check_median", "func_src_before": "    def test_check_median(self):\n        a = np.arange(100).astype('f')\n        a = np.pad(a, (25, 20), 'median')\n        b = np.array(\n            [49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5,\n             49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5,\n             49.5, 49.5, 49.5, 49.5, 49.5,\n\n             0., 1., 2., 3., 4., 5., 6., 7., 8., 9.,\n             10., 11., 12., 13., 14., 15., 16., 17., 18., 19.,\n             20., 21., 22., 23., 24., 25., 26., 27., 28., 29.,\n             30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n             40., 41., 42., 43., 44., 45., 46., 47., 48., 49.,\n             50., 51., 52., 53., 54., 55., 56., 57., 58., 59.,\n             60., 61., 62., 63., 64., 65., 66., 67., 68., 69.,\n             70., 71., 72., 73., 74., 75., 76., 77., 78., 79.,\n             80., 81., 82., 83., 84., 85., 86., 87., 88., 89.,\n             90., 91., 92., 93., 94., 95., 96., 97., 98., 99.,\n\n             49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5,\n             49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5]\n            )\n        assert_array_equal(a, b)", "func_src_after": "    def test_to_csv_float_format_over_decimal(self):\n        # GH#47436\n        df = DataFrame({\"a\": [0.5, 1.0]})\n        result = df.to_csv(\n            decimal=\",\",\n            float_format=lambda x: np.format_float_positional(x, trim=\"-\"),\n            index=False,\n        )\n        expected_rows = [\"a\", \"0.5\", \"1\"]\n        expected = tm.convert_rows_list_to_csv_str(expected_rows)\n        assert result == expected", "line_changes": {"deleted": [{"line_no": 2, "char_start": 33, "char_end": 71, "line": "        a = np.arange(100).astype('f')"}, {"line_no": 4, "char_start": 114, "char_end": 135, "line": "        b = np.array("}, {"line_no": 5, "char_start": 136, "char_end": 208, "line": "            [49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5,"}, {"line_no": 6, "char_start": 209, "char_end": 281, "line": "             49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5,"}, {"line_no": 7, "char_start": 282, "char_end": 324, "line": "             49.5, 49.5, 49.5, 49.5, 49.5,"}, {"line_no": 16, "char_start": 757, "char_end": 819, "line": "             70., 71., 72., 73., 74., 75., 76., 77., 78., 79.,"}, {"line_no": 17, "char_start": 820, "char_end": 882, "line": "             80., 81., 82., 83., 84., 85., 86., 87., 88., 89.,"}, {"line_no": 18, "char_start": 883, "char_end": 945, "line": "             90., 91., 92., 93., 94., 95., 96., 97., 98., 99.,"}], "added": [{"line_no": 2, "char_start": 53, "char_end": 71, "line": "        # GH#47436"}, {"line_no": 3, "char_start": 72, "char_end": 113, "line": "        df = DataFrame({\"a\": [0.5, 1.0]})"}, {"line_no": 4, "char_start": 114, "char_end": 141, "line": "        result = df.to_csv("}, {"line_no": 5, "char_start": 142, "char_end": 166, "line": "            decimal=\",\","}, {"line_no": 6, "char_start": 167, "char_end": 242, "line": "            float_format=lambda x: np.format_float_positional(x, trim=\"-\"),"}, {"line_no": 7, "char_start": 243, "char_end": 267, "line": "            index=False,"}, {"line_no": 8, "char_start": 268, "char_end": 277, "line": "        )"}, {"line_no": 9, "char_start": 278, "char_end": 319, "line": "        expected_rows = [\"a\", \"0.5\", \"1\"]"}, {"line_no": 10, "char_start": 320, "char_end": 385, "line": "        expected = tm.convert_rows_list_to_csv_str(expected_rows)"}, {"line_no": 11, "char_start": 386, "char_end": 419, "line": "        assert result == expected"}]}, "char_changes": {"deleted": [{"char_start": 13, "char_end": 71, "chars": "check_median(self):\n        a = np.arange(100).astype('f')"}, {"char_start": 80, "char_end": 81, "chars": "a"}, {"char_start": 84, "char_end": 755, "chars": "np.pad(a, (25, 20), 'median')\n        b = np.array(\n            [49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5,\n             49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5,\n             49.5, 49.5, 49.5, 49.5, 49.5,\n\n             0., 1., 2., 3., 4., 5., 6., 7., 8., 9.,\n             10., 11., 12., 13., 14., 15., 16., 17., 18., 19.,\n             20., 21., 22., 23., 24., 25., 26., 27., 28., 29.,\n             30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n             40., 41., 42., 43., 44., 45., 46., 47., 48., 49.,\n             50., 51., 52., 53., 54., 55., 56., 57., 58., 59.,\n             60., 61., 62., 63., 64., 65., 66., 67., 68., 69."}, {"char_start": 770, "char_end": 1139, "chars": "70., 71., 72., 73., 74., 75., 76., 77., 78., 79.,\n             80., 81., 82., 83., 84., 85., 86., 87., 88., 89.,\n             90., 91., 92., 93., 94., 95., 96., 97., 98., 99.,\n\n             49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5,\n             49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5, 49.5]\n            )\n        assert_array_equal(a, b)"}], "added": [{"char_start": 13, "char_end": 419, "chars": "to_csv_float_format_over_decimal(self):\n        # GH#47436\n        df = DataFrame({\"a\": [0.5, 1.0]})\n        result = df.to_csv(\n            decimal=\",\",\n            float_format=lambda x: np.format_float_positional(x, trim=\"-\"),\n            index=False,\n        )\n        expected_rows = [\"a\", \"0.5\", \"1\"]\n        expected = tm.convert_rows_list_to_csv_str(expected_rows)\n        assert result == expected"}]}}
{"func_name": "test_shares_memory_api", "func_src_before": "def test_shares_memory_api():\n    x = np.zeros([4, 5, 6], dtype=np.int8)\n\n    assert_equal(np.shares_memory(x, x), True)\n    assert_equal(np.shares_memory(x, x.copy()), False)\n\n    a = x[:,::2,::3]\n    b = x[:,::3,::2]\n    assert_equal(np.shares_memory(a, b), True)\n    assert_equal(np.shares_memory(a, b, max_work=None), True)\n    assert_raises(\n        np.exceptions.TooHardError, np.shares_memory, a, b, max_work=1\n    )", "func_src_after": "    def _str_contains(\n        self, pat, case: bool = True, flags: int = 0, na=None, regex: bool = True\n    ):\n        pass", "line_changes": {"deleted": [{"line_no": 1, "char_start": 1, "char_end": 30, "line": "def test_shares_memory_api():"}, {"line_no": 2, "char_start": 30, "char_end": 72, "line": "    x = np.zeros([4, 5, 6], dtype=np.int8)"}, {"line_no": 11, "char_start": 328, "char_end": 346, "line": "    assert_raises("}, {"line_no": 12, "char_start": 347, "char_end": 417, "line": "        np.exceptions.TooHardError, np.shares_memory, a, b, max_work=1"}, {"line_no": 13, "char_start": 418, "char_end": 423, "line": "    )"}], "added": [{"line_no": 1, "char_start": 1, "char_end": 23, "line": "    def _str_contains("}, {"line_no": 3, "char_start": 105, "char_end": 111, "line": "    ):"}, {"line_no": 4, "char_start": 112, "char_end": 124, "line": "        pass"}]}, "char_changes": {"deleted": [{"char_start": 0, "char_end": 321, "chars": "def test_shares_memory_api():\n    x = np.zeros([4, 5, 6], dtype=np.int8)\n\n    assert_equal(np.shares_memory(x, x), True)\n    assert_equal(np.shares_memory(x, x.copy()), False)\n\n    a = x[:,::2,::3]\n    b = x[:,::3,::2]\n    assert_equal(np.shares_memory(a, b), True)\n    assert_equal(np.shares_memory(a, b, max_work=None),"}, {"char_start": 326, "char_end": 327, "chars": ")"}, {"char_start": 332, "char_end": 423, "chars": "assert_raises(\n        np.exceptions.TooHardError, np.shares_memory, a, b, max_work=1\n    )"}], "added": [{"char_start": 0, "char_end": 99, "chars": "    def _str_contains(\n        self, pat, case: bool = True, flags: int = 0, na=None, regex: bool ="}, {"char_start": 109, "char_end": 124, "chars": "):\n        pass"}]}}
{"func_name": "test_scalar_format.test_einsum_failed_on_p9_and_s390x", "func_src_before": "    def test_einsum_failed_on_p9_and_s390x(self):\n        # Issues gh-14692 and gh-12689\n        # Bug with signed vs unsigned char errored on power9 and s390x Linux\n        tensor = np.random.random_sample((10, 10, 10, 10))\n        x = np.einsum('ijij->', tensor)\n        y = tensor.trace(axis1=0, axis2=2).trace()\n        assert_allclose(x, y)", "func_src_after": "def test_identity(klass, value):\n    assert klass(value) is NaT", "line_changes": {"deleted": [{"line_no": 2, "char_start": 50, "char_end": 88, "line": "        # Issues gh-14692 and gh-12689"}, {"line_no": 3, "char_start": 89, "char_end": 165, "line": "        # Bug with signed vs unsigned char errored on power9 and s390x Linux"}, {"line_no": 4, "char_start": 166, "char_end": 224, "line": "        tensor = np.random.random_sample((10, 10, 10, 10))"}, {"line_no": 5, "char_start": 225, "char_end": 264, "line": "        x = np.einsum('ijij->', tensor)"}, {"line_no": 6, "char_start": 265, "char_end": 315, "line": "        y = tensor.trace(axis1=0, axis2=2).trace()"}, {"line_no": 7, "char_start": 316, "char_end": 345, "line": "        assert_allclose(x, y)"}], "added": [{"line_no": 2, "char_start": 33, "char_end": 63, "line": "    assert klass(value) is NaT"}]}, "char_changes": {"deleted": [{"char_start": 0, "char_end": 4, "chars": "    "}, {"char_start": 13, "char_end": 345, "chars": "einsum_failed_on_p9_and_s390x(self):\n        # Issues gh-14692 and gh-12689\n        # Bug with signed vs unsigned char errored on power9 and s390x Linux\n        tensor = np.random.random_sample((10, 10, 10, 10))\n        x = np.einsum('ijij->', tensor)\n        y = tensor.trace(axis1=0, axis2=2).trace()\n        assert_allclose(x, y)"}], "added": [{"char_start": 9, "char_end": 63, "chars": "identity(klass, value):\n    assert klass(value) is NaT"}]}}
{"func_name": "dirty_lock.time_choice", "func_src_before": "    def time_choice(self, v):\n        self.rng.choice(self.a, 1000, replace=False)", "func_src_after": "    def test_to_datetime_on_datetime64_series(self, cache):\n        # #2699\n        ser = Series(date_range(\"1/1/2000\", periods=10))\n\n        result = to_datetime(ser, cache=cache)\n        assert result[0] == ser[0]", "line_changes": {"deleted": [], "added": [{"line_no": 2, "char_start": 60, "char_end": 75, "line": "        # #2699"}]}, "char_changes": {"deleted": [{"char_start": 9, "char_end": 19, "chars": "ime_choice"}, {"char_start": 26, "char_end": 27, "chars": "v"}, {"char_start": 38, "char_end": 63, "chars": "self.rng.choice(self.a, 1"}, {"char_start": 68, "char_end": 82, "chars": "replace=False)"}], "added": [{"char_start": 9, "char_end": 45, "chars": "est_to_datetime_on_datetime64_series"}, {"char_start": 52, "char_end": 57, "chars": "cache"}, {"char_start": 68, "char_end": 114, "chars": "# #2699\n        ser = Series(date_range(\"1/1/2"}, {"char_start": 117, "char_end": 118, "chars": "\""}, {"char_start": 120, "char_end": 215, "chars": "periods=10))\n\n        result = to_datetime(ser, cache=cache)\n        assert result[0] == ser[0]"}]}}
{"func_name": "test_non_spawnable.test_int64_uint64_corner_case", "func_src_before": "    def test_int64_uint64_corner_case(self):\n        # When stored in Numpy arrays, `lbnd` is casted\n        # as np.int64, and `ubnd` is casted as np.uint64.\n        # Checking whether `lbnd` >= `ubnd` used to be\n        # done solely via direct comparison, which is incorrect\n        # because when Numpy tries to compare both numbers,\n        # it casts both to np.float64 because there is\n        # no integer superset of np.int64 and np.uint64. However,\n        # `ubnd` is too large to be represented in np.float64,\n        # causing it be round down to np.iinfo(np.int64).max,\n        # leading to a ValueError because `lbnd` now equals\n        # the new `ubnd`.\n\n        dt = np.int64\n        tgt = np.iinfo(np.int64).max\n        lbnd = np.int64(np.iinfo(np.int64).max)\n        ubnd = np.uint64(np.iinfo(np.int64).max + 1)\n\n        # None of these function calls should\n        # generate a ValueError now.\n        actual = np.random.randint(lbnd, ubnd, dtype=dt)\n        assert_equal(actual, tgt)", "func_src_after": "    def test_compare_invalid_scalar(self, box_with_array, scalar):\n        # GH#28980\n        # comparison with scalar that cannot be interpreted as a Period\n        pi = period_range(\"2000\", periods=4)\n        parr = tm.box_expected(pi, box_with_array)\n        assert_invalid_comparison(parr, scalar, box_with_array)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 101, "char_end": 158, "line": "        # as np.int64, and `ubnd` is casted as np.uint64."}, {"line_no": 4, "char_start": 159, "char_end": 213, "line": "        # Checking whether `lbnd` >= `ubnd` used to be"}, {"line_no": 6, "char_start": 278, "char_end": 337, "line": "        # because when Numpy tries to compare both numbers,"}, {"line_no": 7, "char_start": 338, "char_end": 392, "line": "        # it casts both to np.float64 because there is"}, {"line_no": 8, "char_start": 393, "char_end": 458, "line": "        # no integer superset of np.int64 and np.uint64. However,"}, {"line_no": 9, "char_start": 459, "char_end": 521, "line": "        # `ubnd` is too large to be represented in np.float64,"}, {"line_no": 10, "char_start": 522, "char_end": 583, "line": "        # causing it be round down to np.iinfo(np.int64).max,"}, {"line_no": 11, "char_start": 584, "char_end": 643, "line": "        # leading to a ValueError because `lbnd` now equals"}, {"line_no": 12, "char_start": 644, "char_end": 669, "line": "        # the new `ubnd`."}], "added": [{"line_no": 2, "char_start": 67, "char_end": 85, "line": "        # GH#28980"}, {"line_no": 4, "char_start": 158, "char_end": 202, "line": "        pi = period_range(\"2000\", periods=4)"}, {"line_no": 5, "char_start": 203, "char_end": 253, "line": "        parr = tm.box_expected(pi, box_with_array)"}, {"line_no": 6, "char_start": 254, "char_end": 317, "line": "        assert_invalid_comparison(parr, scalar, box_with_array)"}]}, "char_changes": {"deleted": [{"char_start": 13, "char_end": 76, "chars": "int64_uint64_corner_case(self):\n        # When stored in Numpy "}, {"char_start": 81, "char_end": 82, "chars": "s"}, {"char_start": 84, "char_end": 246, "chars": "`lbnd` is casted\n        # as np.int64, and `ubnd` is casted as np.uint64.\n        # Checking whether `lbnd` >= `ubnd` used to be\n        # done solely via direct"}, {"char_start": 257, "char_end": 258, "chars": ","}, {"char_start": 260, "char_end": 1004, "chars": "hich is incorrect\n        # because when Numpy tries to compare both numbers,\n        # it casts both to np.float64 because there is\n        # no integer superset of np.int64 and np.uint64. However,\n        # `ubnd` is too large to be represented in np.float64,\n        # causing it be round down to np.iinfo(np.int64).max,\n        # leading to a ValueError because `lbnd` now equals\n        # the new `ubnd`.\n\n        dt = np.int64\n        tgt = np.iinfo(np.int64).max\n        lbnd = np.int64(np.iinfo(np.int64).max)\n        ubnd = np.uint64(np.iinfo(np.int64).max + 1)\n\n        # None of these function calls should\n        # generate a ValueError now.\n        actual = np.random.randint(lbnd, ubnd, dtype=dt)\n        assert_equal(actual, tgt"}], "added": [{"char_start": 13, "char_end": 51, "chars": "compare_invalid_scalar(self, box_with_"}, {"char_start": 58, "char_end": 95, "chars": "scalar):\n        # GH#28980\n        #"}, {"char_start": 108, "char_end": 316, "chars": "ith scalar that cannot be interpreted as a Period\n        pi = period_range(\"2000\", periods=4)\n        parr = tm.box_expected(pi, box_with_array)\n        assert_invalid_comparison(parr, scalar, box_with_array"}]}}
{"func_name": "endpoint.test_uniform_neg_range", "func_src_before": "    def test_uniform_neg_range(self):\n        func = random.uniform\n        assert_raises(ValueError, func, 2, 1)\n        assert_raises(ValueError, func,  [1, 2], [1, 1])\n        assert_raises(ValueError, func,  [[0, 1],[2, 3]], 2)\n\n            def __float__(self):\n                raise TypeError\n\n            def __int__(self):\n                raise TypeError", "func_src_after": "        def float_result_type(dtype, dtype2):\n            typs = {dtype.kind, dtype2.kind}\n            if not len(typs - {\"f\", \"i\", \"u\"}) and (\n                dtype.kind == \"f\" or dtype2.kind == \"f\"\n            ):\n                return \"f\"\n            return None", "line_changes": {"deleted": [{"line_no": 2, "char_start": 38, "char_end": 67, "line": "        func = random.uniform"}, {"line_no": 3, "char_start": 68, "char_end": 113, "line": "        assert_raises(ValueError, func, 2, 1)"}, {"line_no": 4, "char_start": 114, "char_end": 170, "line": "        assert_raises(ValueError, func,  [1, 2], [1, 1])"}, {"line_no": 5, "char_start": 171, "char_end": 231, "line": "        assert_raises(ValueError, func,  [[0, 1],[2, 3]], 2)"}, {"line_no": 8, "char_start": 266, "char_end": 297, "line": "                raise TypeError"}], "added": [{"line_no": 2, "char_start": 46, "char_end": 90, "line": "            typs = {dtype.kind, dtype2.kind}"}, {"line_no": 3, "char_start": 91, "char_end": 143, "line": "            if not len(typs - {\"f\", \"i\", \"u\"}) and ("}, {"line_no": 4, "char_start": 144, "char_end": 199, "line": "                dtype.kind == \"f\" or dtype2.kind == \"f\""}, {"line_no": 5, "char_start": 200, "char_end": 214, "line": "            ):"}, {"line_no": 6, "char_start": 215, "char_end": 241, "line": "                return \"f\""}, {"line_no": 7, "char_start": 242, "char_end": 265, "line": "            return None"}]}, "char_changes": {"deleted": [{"char_start": 8, "char_end": 265, "chars": "test_uniform_neg_range(self):\n        func = random.uniform\n        assert_raises(ValueError, func, 2, 1)\n        assert_raises(ValueError, func,  [1, 2], [1, 1])\n        assert_raises(ValueError, func,  [[0, 1],[2, 3]], 2)\n\n            def __float__(self):"}, {"char_start": 282, "char_end": 361, "chars": "raise TypeError\n\n            def __int__(self):\n                raise TypeError"}], "added": [{"char_start": 0, "char_end": 4, "chars": "    "}, {"char_start": 12, "char_end": 199, "chars": "float_result_type(dtype, dtype2):\n            typs = {dtype.kind, dtype2.kind}\n            if not len(typs - {\"f\", \"i\", \"u\"}) and (\n                dtype.kind == \"f\" or dtype2.kind == \"f\""}, {"char_start": 212, "char_end": 215, "chars": "):\n"}, {"char_start": 219, "char_end": 265, "chars": "            return \"f\"\n            return None"}]}}
{"func_name": "assert_mask_equal.assert_mask_equal.test_dot_out.myfunc", "func_src_before": "        def myfunc(b):\n            return b[1]", "func_src_after": "            def types_mapper(dtype):\n                dtype_dict = self.kwds[\"dtype\"]\n                if dtype_dict is not None and dtype_dict.get(dtype, None) is not None:\n                    return dtype_dict.get(dtype)\n                return arrow_string_types_mapper()(dtype)", "line_changes": {"deleted": [{"line_no": 1, "char_start": 1, "char_end": 23, "line": "        def myfunc(b):"}, {"line_no": 2, "char_start": 23, "char_end": 46, "line": "            return b[1]"}], "added": [{"line_no": 1, "char_start": 1, "char_end": 37, "line": "            def types_mapper(dtype):"}, {"line_no": 2, "char_start": 37, "char_end": 84, "line": "                dtype_dict = self.kwds[\"dtype\"]"}, {"line_no": 3, "char_start": 85, "char_end": 171, "line": "                if dtype_dict is not None and dtype_dict.get(dtype, None) is not None:"}, {"line_no": 4, "char_start": 172, "char_end": 220, "line": "                    return dtype_dict.get(dtype)"}, {"line_no": 5, "char_start": 221, "char_end": 278, "line": "                return arrow_string_types_mapper()(dtype)"}]}, "char_changes": {"deleted": [{"char_start": 8, "char_end": 46, "chars": "def myfunc(b):\n            return b[1]"}], "added": [{"char_start": 8, "char_end": 278, "chars": "    def types_mapper(dtype):\n                dtype_dict = self.kwds[\"dtype\"]\n                if dtype_dict is not None and dtype_dict.get(dtype, None) is not None:\n                    return dtype_dict.get(dtype)\n                return arrow_string_types_mapper()(dtype)"}]}}
{"func_name": "__dir__.__init__", "func_src_before": "    def __init__(sef, *args, **kwargs):\n        warnings.warn(\n            \"distutils has been deprecated since NumPy 1.26.x\"\n            \"Use the Meson backend instead, or generate wrappers\"\n            \"without -c and use a custom build script\",\n            VisibleDeprecationWarning,\n            stacklevel=2,\n        )\n        super().__init__(*args, **kwargs)", "func_src_after": "    def _insert_inaxis_grouper(self, result: Series | DataFrame) -> DataFrame:\n        if isinstance(result, Series):\n            result = result.to_frame()\n\n        # zip in reverse so we can always insert at loc 0\n        columns = result.columns\n        for name, lev, in_axis in zip(\n            reversed(self.grouper.names),\n            reversed(self.grouper.get_group_levels()),\n            reversed([grp.in_axis for grp in self.grouper.groupings]),\n        ):\n            # GH #28549\n            # When using .apply(-), name will be in columns already\n            if name not in columns:\n                if in_axis:\n                    result.insert(0, name, lev)\n                else:\n                    msg = (\n                        \"A grouping was used that is not in the columns of the \"\n                        \"DataFrame and so was excluded from the result. This grouping \"\n                        \"will be included in a future version of pandas. Add the \"\n                        \"grouping as a column of the DataFrame to silence this warning.\"\n                    )\n                    warnings.warn(\n                        message=msg,\n                        category=FutureWarning,\n                        stacklevel=find_stack_level(),\n                    )\n\n        return result", "line_changes": {"deleted": [{"line_no": 2, "char_start": 40, "char_end": 62, "line": "        warnings.warn("}, {"line_no": 3, "char_start": 63, "char_end": 125, "line": "            \"distutils has been deprecated since NumPy 1.26.x\""}, {"line_no": 4, "char_start": 126, "char_end": 191, "line": "            \"Use the Meson backend instead, or generate wrappers\""}, {"line_no": 5, "char_start": 192, "char_end": 247, "line": "            \"without -c and use a custom build script\","}, {"line_no": 9, "char_start": 323, "char_end": 364, "line": "        super().__init__(*args, **kwargs)"}], "added": [{"line_no": 3, "char_start": 118, "char_end": 156, "line": "            result = result.to_frame()"}, {"line_no": 29, "char_start": 1281, "char_end": 1281, "line": ""}, {"line_no": 30, "char_start": 1282, "char_end": 1303, "line": "        return result"}]}, "char_changes": {"deleted": [{"char_start": 8, "char_end": 9, "chars": "_"}, {"char_start": 12, "char_end": 16, "chars": "it__"}, {"char_start": 22, "char_end": 278, "chars": "*args, **kwargs):\n        warnings.warn(\n            \"distutils has been deprecated since NumPy 1.26.x\"\n            \"Use the Meson backend instead, or generate wrappers\"\n            \"without -c and use a custom build script\",\n            VisibleDeprecation"}, {"char_start": 310, "char_end": 313, "chars": "2,\n"}, {"char_start": 331, "char_end": 364, "chars": "super().__init__(*args, **kwargs)"}], "added": [{"char_start": 9, "char_end": 30, "chars": "insert_inaxis_grouper"}, {"char_start": 33, "char_end": 34, "chars": "l"}, {"char_start": 37, "char_end": 114, "chars": "result: Series | DataFrame) -> DataFrame:\n        if isinstance(result, Serie"}, {"char_start": 126, "char_end": 127, "chars": " "}, {"char_start": 127, "char_end": 1195, "chars": "   result = result.to_frame()\n\n        # zip in reverse so we can always insert at loc 0\n        columns = result.columns\n        for name, lev, in_axis in zip(\n            reversed(self.grouper.names),\n            reversed(self.grouper.get_group_levels()),\n            reversed([grp.in_axis for grp in self.grouper.groupings]),\n        ):\n            # GH #28549\n            # When using .apply(-), name will be in columns already\n            if name not in columns:\n                if in_axis:\n                    result.insert(0, name, lev)\n                else:\n                    msg = (\n                        \"A grouping was used that is not in the columns of the \"\n                        \"DataFrame and so was excluded from the result. This grouping \"\n                        \"will be included in a future version of pandas. Add the \"\n                        \"grouping as a column of the DataFrame to silence this warning.\"\n                    )\n                    warnings.warn(\n                        message=msg,\n                        category=Future"}, {"char_start": 1216, "char_end": 1223, "chars": "       "}, {"char_start": 1223, "char_end": 1228, "chars": "     "}, {"char_start": 1239, "char_end": 1271, "chars": "find_stack_level(),\n            "}, {"char_start": 1281, "char_end": 1282, "chars": "\n"}, {"char_start": 1290, "char_end": 1303, "chars": "return result"}]}}
{"func_name": "_assert_equal_type_and_value.test_inplace", "func_src_before": "    def test_inplace(self):\n        array_like = ArrayLike(np.array([0]))\n        array_like += 1\n        _assert_equal_type_and_value(array_like, ArrayLike(np.array([1])))\n\n        array = np.array([0])\n        array += ArrayLike(1)\n        _assert_equal_type_and_value(array, ArrayLike(np.array([1])))\n\n            def __add__(self, other):\n                return self\n\n            def __radd__(self, other):\n                return self", "func_src_after": "    def test_astype_array_fallback(self):\n        obj = period_range(\"2000\", periods=2, name=\"idx\")\n        result = obj.astype(bool)\n        expected = Index(np.array([True, True]), name=\"idx\")\n        tm.assert_index_equal(result, expected)\n\n        result = obj._data.astype(bool)\n        expected = np.array([True, True])\n        tm.assert_numpy_array_equal(result, expected)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 28, "char_end": 73, "line": "        array_like = ArrayLike(np.array([0]))"}, {"line_no": 3, "char_start": 74, "char_end": 97, "line": "        array_like += 1"}, {"line_no": 4, "char_start": 98, "char_end": 172, "line": "        _assert_equal_type_and_value(array_like, ArrayLike(np.array([1])))"}], "added": [{"line_no": 2, "char_start": 42, "char_end": 99, "line": "        obj = period_range(\"2000\", periods=2, name=\"idx\")"}, {"line_no": 3, "char_start": 100, "char_end": 133, "line": "        result = obj.astype(bool)"}, {"line_no": 4, "char_start": 134, "char_end": 194, "line": "        expected = Index(np.array([True, True]), name=\"idx\")"}]}, "char_changes": {"deleted": [{"char_start": 13, "char_end": 17, "chars": "inpl"}, {"char_start": 19, "char_end": 20, "chars": "e"}, {"char_start": 36, "char_end": 232, "chars": "array_like = ArrayLike(np.array([0]))\n        array_like += 1\n        _assert_equal_type_and_value(array_like, ArrayLike(np.array([1])))\n\n        array = np.array([0])\n        array += ArrayLike(1"}, {"char_start": 242, "char_end": 243, "chars": "_"}, {"char_start": 250, "char_end": 438, "chars": "equal_type_and_value(array, ArrayLike(np.array([1])))\n\n            def __add__(self, other):\n                return self\n\n            def __radd__(self, other):\n                return self"}], "added": [{"char_start": 13, "char_end": 31, "chars": "astype_array_fallb"}, {"char_start": 33, "char_end": 34, "chars": "k"}, {"char_start": 50, "char_end": 193, "chars": "obj = period_range(\"2000\", periods=2, name=\"idx\")\n        result = obj.astype(bool)\n        expected = Index(np.array([True, True]), name=\"idx\""}, {"char_start": 203, "char_end": 206, "chars": "tm."}, {"char_start": 213, "char_end": 379, "chars": "index_equal(result, expected)\n\n        result = obj._data.astype(bool)\n        expected = np.array([True, True])\n        tm.assert_numpy_array_equal(result, expected)"}]}}
{"func_name": "_text_to_list.setup_class", "func_src_before": "    def setup_class(self, tmp_path_factory):\n        file = tmp_path_factory.mktemp(\"runtime_test_script\")\n        file /= \"_runtime_detect.py\"\n        file.write_text(self.SCRIPT)\n        self.file = file\n        return", "func_src_after": "    def _initialize_index_label(self, index_label: IndexLabel | None) -> IndexLabel:\n        if index_label is not False:\n            if index_label is None:\n                return self._get_index_label_from_obj()\n            elif not isinstance(index_label, (list, tuple, np.ndarray, ABCIndex)):\n                # given a string for a DF with Index\n                return [index_label]\n        return index_label", "line_changes": {"deleted": [{"line_no": 2, "char_start": 45, "char_end": 106, "line": "        file = tmp_path_factory.mktemp(\"runtime_test_script\")"}, {"line_no": 3, "char_start": 107, "char_end": 143, "line": "        file /= \"_runtime_detect.py\""}, {"line_no": 4, "char_start": 144, "char_end": 180, "line": "        file.write_text(self.SCRIPT)"}, {"line_no": 5, "char_start": 181, "char_end": 205, "line": "        self.file = file"}], "added": [{"line_no": 2, "char_start": 85, "char_end": 121, "line": "        if index_label is not False:"}, {"line_no": 3, "char_start": 122, "char_end": 157, "line": "            if index_label is None:"}, {"line_no": 4, "char_start": 158, "char_end": 213, "line": "                return self._get_index_label_from_obj()"}, {"line_no": 5, "char_start": 214, "char_end": 296, "line": "            elif not isinstance(index_label, (list, tuple, np.ndarray, ABCIndex)):"}, {"line_no": 6, "char_start": 297, "char_end": 349, "line": "                # given a string for a DF with Index"}, {"line_no": 7, "char_start": 350, "char_end": 386, "line": "                return [index_label]"}]}, "char_changes": {"deleted": [{"char_start": 8, "char_end": 205, "chars": "setup_class(self, tmp_path_factory):\n        file = tmp_path_factory.mktemp(\"runtime_test_script\")\n        file /= \"_runtime_detect.py\"\n        file.write_text(self.SCRIPT)\n        self.file = file"}], "added": [{"char_start": 8, "char_end": 386, "chars": "_initialize_index_label(self, index_label: IndexLabel | None) -> IndexLabel:\n        if index_label is not False:\n            if index_label is None:\n                return self._get_index_label_from_obj()\n            elif not isinstance(index_label, (list, tuple, np.ndarray, ABCIndex)):\n                # given a string for a DF with Index\n                return [index_label]"}, {"char_start": 401, "char_end": 413, "chars": " index_label"}]}}
